{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/dataset.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Num', 'Timestamp', 'Current_J0', 'Temperature_T0', 'Current_J1',\n",
       "       'Temperature_J1', 'Current_J2', 'Temperature_J2', 'Current_J3',\n",
       "       'Temperature_J3', 'Current_J4', 'Temperature_J4', 'Current_J5',\n",
       "       'Temperature_J5', 'Speed_J0', 'Speed_J1', 'Speed_J2', 'Speed_J3',\n",
       "       'Speed_J4', 'Speed_J5', 'Tool_current', 'cycle ',\n",
       "       'Robot_ProtectiveStop', 'grip_lost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current_J0</th>\n",
       "      <th>Temperature_T0</th>\n",
       "      <th>Current_J1</th>\n",
       "      <th>Temperature_J1</th>\n",
       "      <th>Current_J2</th>\n",
       "      <th>Temperature_J2</th>\n",
       "      <th>Current_J3</th>\n",
       "      <th>Temperature_J3</th>\n",
       "      <th>Current_J4</th>\n",
       "      <th>Temperature_J4</th>\n",
       "      <th>Current_J5</th>\n",
       "      <th>Temperature_J5</th>\n",
       "      <th>Speed_J0</th>\n",
       "      <th>Speed_J1</th>\n",
       "      <th>Speed_J2</th>\n",
       "      <th>Speed_J3</th>\n",
       "      <th>Speed_J4</th>\n",
       "      <th>Speed_J5</th>\n",
       "      <th>Tool_current</th>\n",
       "      <th>grip_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109628</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-2.024669</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-1.531442</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-0.998570</td>\n",
       "      <td>32.1250</td>\n",
       "      <td>-0.062540</td>\n",
       "      <td>32.2500</td>\n",
       "      <td>-0.152622</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>2.955651e-01</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>-0.132836</td>\n",
       "      <td>-0.007479</td>\n",
       "      <td>-1.529622e-01</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.595605</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-2.278456</td>\n",
       "      <td>29.3125</td>\n",
       "      <td>-0.866556</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-0.206097</td>\n",
       "      <td>32.1875</td>\n",
       "      <td>-1.062762</td>\n",
       "      <td>32.2500</td>\n",
       "      <td>-0.260764</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>-7.391485e-30</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>4.169016e-04</td>\n",
       "      <td>0.505895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.229474</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-2.800408</td>\n",
       "      <td>29.3125</td>\n",
       "      <td>-2.304336</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-0.351499</td>\n",
       "      <td>32.1250</td>\n",
       "      <td>-0.668869</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>0.039071</td>\n",
       "      <td>32.0625</td>\n",
       "      <td>1.369386e-01</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>-2.535874</td>\n",
       "      <td>0.379867</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>-4.968559e-01</td>\n",
       "      <td>0.079420</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065053</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-3.687768</td>\n",
       "      <td>29.3125</td>\n",
       "      <td>-1.217652</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-1.209115</td>\n",
       "      <td>32.1250</td>\n",
       "      <td>-0.819755</td>\n",
       "      <td>32.2500</td>\n",
       "      <td>0.153903</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>-9.030032e-02</td>\n",
       "      <td>-0.004911</td>\n",
       "      <td>-0.009096</td>\n",
       "      <td>-0.384196</td>\n",
       "      <td>0.018411</td>\n",
       "      <td>4.255591e-01</td>\n",
       "      <td>0.083325</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.884140</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-2.938830</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-1.794076</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-2.356471</td>\n",
       "      <td>32.1875</td>\n",
       "      <td>-0.966427</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>0.178998</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>1.268088e-01</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>-0.353284</td>\n",
       "      <td>0.014994</td>\n",
       "      <td>1.809886e-01</td>\n",
       "      <td>0.086379</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.118961</td>\n",
       "      <td>27.8125</td>\n",
       "      <td>-2.162542</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-1.211779</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-0.481834</td>\n",
       "      <td>32.1875</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>0.064844</td>\n",
       "      <td>32.0625</td>\n",
       "      <td>-4.639511e-05</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>-2.470161e-03</td>\n",
       "      <td>0.188310</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086138</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-1.757647</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-0.960634</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-0.488380</td>\n",
       "      <td>32.1875</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>0.053249</td>\n",
       "      <td>32.0625</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.121039e-44</td>\n",
       "      <td>0.085192</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.075657</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-1.836465</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-0.961322</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-0.512541</td>\n",
       "      <td>32.1875</td>\n",
       "      <td>-0.021845</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>0.039228</td>\n",
       "      <td>32.0625</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.087058</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.186848</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-2.563738</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-1.418934</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-0.262015</td>\n",
       "      <td>32.1875</td>\n",
       "      <td>0.099942</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>-0.173527</td>\n",
       "      <td>32.0625</td>\n",
       "      <td>-1.660036e-01</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>-0.015483</td>\n",
       "      <td>0.350063</td>\n",
       "      <td>-0.009986</td>\n",
       "      <td>-1.927102e-01</td>\n",
       "      <td>0.085785</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.158912</td>\n",
       "      <td>27.8750</td>\n",
       "      <td>-1.750777</td>\n",
       "      <td>29.3750</td>\n",
       "      <td>-1.979400</td>\n",
       "      <td>29.4375</td>\n",
       "      <td>-0.184550</td>\n",
       "      <td>32.1875</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>32.3125</td>\n",
       "      <td>-0.209541</td>\n",
       "      <td>32.0625</td>\n",
       "      <td>9.832304e-02</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>-0.016996</td>\n",
       "      <td>0.496241</td>\n",
       "      <td>-0.017353</td>\n",
       "      <td>-5.886860e-01</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current_J0  Temperature_T0  Current_J1  Temperature_J1  Current_J2  \\\n",
       "0    0.109628         27.8750   -2.024669         29.3750   -1.531442   \n",
       "1    0.595605         27.8750   -2.278456         29.3125   -0.866556   \n",
       "2   -0.229474         27.8750   -2.800408         29.3125   -2.304336   \n",
       "3    0.065053         27.8750   -3.687768         29.3125   -1.217652   \n",
       "4    0.884140         27.8750   -2.938830         29.3750   -1.794076   \n",
       "5    0.118961         27.8125   -2.162542         29.3750   -1.211779   \n",
       "6    0.086138         27.8750   -1.757647         29.3750   -0.960634   \n",
       "7    0.075657         27.8750   -1.836465         29.3750   -0.961322   \n",
       "8   -0.186848         27.8750   -2.563738         29.3750   -1.418934   \n",
       "9   -0.158912         27.8750   -1.750777         29.3750   -1.979400   \n",
       "\n",
       "   Temperature_J2  Current_J3  Temperature_J3  Current_J4  Temperature_J4  \\\n",
       "0         29.3750   -0.998570         32.1250   -0.062540         32.2500   \n",
       "1         29.4375   -0.206097         32.1875   -1.062762         32.2500   \n",
       "2         29.4375   -0.351499         32.1250   -0.668869         32.3125   \n",
       "3         29.4375   -1.209115         32.1250   -0.819755         32.2500   \n",
       "4         29.4375   -2.356471         32.1875   -0.966427         32.3125   \n",
       "5         29.4375   -0.481834         32.1875    0.015318         32.3125   \n",
       "6         29.4375   -0.488380         32.1875    0.006506         32.3125   \n",
       "7         29.4375   -0.512541         32.1875   -0.021845         32.3125   \n",
       "8         29.4375   -0.262015         32.1875    0.099942         32.3125   \n",
       "9         29.4375   -0.184550         32.1875    0.079157         32.3125   \n",
       "\n",
       "   Current_J5  Temperature_J5      Speed_J0  Speed_J1  Speed_J2  Speed_J3  \\\n",
       "0   -0.152622         32.0000  2.955651e-01 -0.000490  0.001310 -0.132836   \n",
       "1   -0.260764         32.0000 -7.391485e-30 -0.000304  0.002185  0.001668   \n",
       "2    0.039071         32.0625  1.369386e-01  0.007795 -2.535874  0.379867   \n",
       "3    0.153903         32.0000 -9.030032e-02 -0.004911 -0.009096 -0.384196   \n",
       "4    0.178998         32.0000  1.268088e-01  0.005567  0.001138 -0.353284   \n",
       "5    0.064844         32.0625 -4.639511e-05  0.000093  0.000262  0.002171   \n",
       "6    0.053249         32.0625  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "7    0.039228         32.0625  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "8   -0.173527         32.0625 -1.660036e-01  0.002409 -0.015483  0.350063   \n",
       "9   -0.209541         32.0625  9.832304e-02  0.004996 -0.016996  0.496241   \n",
       "\n",
       "   Speed_J4      Speed_J5  Tool_current  grip_lost  \n",
       "0 -0.007479 -1.529622e-01      0.082732      False  \n",
       "1 -0.000767  4.169016e-04      0.505895      False  \n",
       "2  0.000455 -4.968559e-01      0.079420      False  \n",
       "3  0.018411  4.255591e-01      0.083325      False  \n",
       "4  0.014994  1.809886e-01      0.086379      False  \n",
       "5  0.000265 -2.470161e-03      0.188310      False  \n",
       "6  0.000000  1.121039e-44      0.085192      False  \n",
       "7  0.000000  0.000000e+00      0.087058      False  \n",
       "8 -0.009986 -1.927102e-01      0.085785      False  \n",
       "9 -0.017353 -5.886860e-01      0.085020      False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop irrelevant columns\n",
    "df.drop([\"Timestamp\", \"Num\", \"cycle \", \"Robot_ProtectiveStop\"], axis=1, inplace=True)\n",
    "\n",
    "# Show data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change grip_lost to binary values instead of boolean falues, only use this cell once otherwise all grip_lost turn to null values\n",
    "df[\"grip_lost\"] = df[\"grip_lost\"].map({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class Distribution:\n",
      "grip_lost\n",
      "0    7166\n",
      "1     243\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Features and target\n",
    "y = df[\"grip_lost\"]\n",
    "X = df.drop([\"grip_lost\"], axis=1)\n",
    "\n",
    "class_counts = y.value_counts()\n",
    "print(\"Original Class Distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.04739934e-01 -2.24610863e-01 -6.39001885e-01 ...  2.45139426e-02\n",
      "  -8.62654817e-04 -2.93865080e-01]\n",
      " [-6.15802452e-03 -2.52392403e+00  6.71725757e-01 ...  2.45139426e-02\n",
      "  -8.62654817e-04 -2.22603657e-01]\n",
      " [ 2.67703523e-01  4.58353444e-01  6.56081181e-01 ... -1.09364484e-02\n",
      "   2.02667114e-02  1.80474950e+00]\n",
      " ...\n",
      " [ 1.70150964e-01 -1.95478711e+00  5.78316098e-01 ...  2.45139426e-02\n",
      "  -8.62654817e-04 -3.12258257e-01]\n",
      " [ 9.45840493e-02  5.72180828e-01  7.07024986e-01 ...  2.45139426e-02\n",
      "  -8.62654817e-04 -3.75968373e-01]\n",
      " [-3.59156944e-01 -1.47671209e+00 -7.33282976e-01 ...  1.85971084e-01\n",
      "   2.86083296e-01 -3.18714984e-01]]\n"
     ]
    }
   ],
   "source": [
    "# normalizing data using numpy\n",
    "\n",
    "# Mean of features\n",
    "mean = np.mean(X_train, axis=0)\n",
    "\n",
    "# std of features\n",
    "std = np.std(X_train, axis=0) \n",
    "\n",
    "# normalize training set\n",
    "X_train_normalized = (X_train - mean) / std\n",
    "\n",
    "# Normalize test set using training set parameters\n",
    "X_test_normalized = (X_test - mean) / std\n",
    "\n",
    "# reshaping y\n",
    "y_train = y_train.values.reshape(-1, 1)  # convert to column vector\n",
    "y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Handle potential NaN or Inf values aftr normalization\n",
    "X_train_normalized = np.nan_to_num(X_train_normalized, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_test_normalized = np.nan_to_num(X_test_normalized, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "# print(\"Any NaN in y_train:\", np.isnan(y_train).any())\n",
    "# print(\"Any Inf in X_train:\", np.isinf(X_train).any())\n",
    "# print(\"Any Inf in y_train:\", np.isinf(y_train).any())\n",
    "\n",
    "print(X_test_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here I am going to build a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN config\n",
    "input_size = X_train.shape[1] # amount of features is the input layer\n",
    "hidden_size = 16 # random set amount of hidden size \n",
    "output_size = 1 # only one output neuron that is binary of course\n",
    "learning_rate = 1e-3\n",
    "epochs = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Sigmoid derivative\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    # Input layer to hidden layer\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    # Hidden layer to output layer\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    A2 = np.clip(A2, 1e-7, 1 - 1e-7)  # Avoid exact 0 or 1 values\n",
    "\n",
    "    \n",
    "    return Z1, A1, Z2, A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, Z1, A1, Z2, A2, W2):\n",
    "    m = X.shape[0] \n",
    "    \n",
    "    # Compute output error\n",
    "    dZ2 = A2 - y.reshape(-1, 1)\n",
    "    dW2 = (1 / m) * np.dot(A1.T, dZ2)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute hidden layer error\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * sigmoid_derivative(A1)\n",
    "    dW1 = (1 / m) * np.dot(X.T, dZ1)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6848\n",
      "Epoch 50, Loss: 0.6350\n",
      "Epoch 100, Loss: 0.5911\n",
      "Epoch 150, Loss: 0.5522\n",
      "Epoch 200, Loss: 0.5178\n",
      "Epoch 250, Loss: 0.4872\n",
      "Epoch 300, Loss: 0.4601\n",
      "Epoch 350, Loss: 0.4358\n",
      "Epoch 400, Loss: 0.4142\n",
      "Epoch 450, Loss: 0.3947\n"
     ]
    }
   ],
   "source": [
    "# Update the training loop to use normalized data\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation on normalized training data\n",
    "    Z1, A1, Z2, A2 = forward_propagation(X_train_normalized, W1, b1, W2, b2)\n",
    "\n",
    "    # Loss function (BCE)\n",
    "    epsilon = 1e-9  # Small constant to avoid log(0)\n",
    "    loss = -np.mean(y_train * np.log(A2 + epsilon) + (1 - y_train) * np.log(1 - A2 + epsilon))\n",
    "\n",
    "    # Backpropagation\n",
    "    dW1, db1, dW2, db2 = backward_propagation(X_train_normalized, y_train, Z1, A1, Z2, A2, W2)\n",
    "\n",
    "    # Gradient Descent (Update Weights)\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "    # Print loss every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9777\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "_, _, _, A2_test = forward_propagation(X_test, W1, b1, W2, b2)\n",
    "y_pred = (A2_test > 0.5).astype(int)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below here is model evaluation here I don't just use numpy and pandas, because too much work and not being that educational.\n",
    "We can see that the model learned to predict the majority class. The test accuracy seems high 0.9777, however this is achieved by predicting only class 0, no grip_lost. This can probably be fixed, but this wasn't the goal of this project, which was building a NN from scratch using only Numpy and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "No Grip Lost       0.98      1.00      0.99      1449\n",
      "   Grip Lost       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.98      1482\n",
      "   macro avg       0.49      0.50      0.49      1482\n",
      "weighted avg       0.96      0.98      0.97      1482\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpjgl\\miniconda3\\envs\\seg3d\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mpjgl\\miniconda3\\envs\\seg3d\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mpjgl\\miniconda3\\envs\\seg3d\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    # Input layer to hidden layer\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = 1 / (1 + np.exp(-Z1))  # Sigmoid activation\n",
    "    \n",
    "    # Hidden layer to output layer\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = 1 / (1 + np.exp(-Z2))  # Sigmoid activation\n",
    "    A2 = np.clip(A2, 1e-7, 1 - 1e-7)  # Clip so we don't get exact 1 or 0 values\n",
    "    \n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Predict on test data using normalized inputs\n",
    "_, _, _, A2_test = forward_propagation(X_test_normalized, W1, b1, W2, b2)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = (A2_test > 0.5).astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    y_test, \n",
    "    y_pred, \n",
    "    target_names=['No Grip Lost', 'Grip Lost']\n",
    ")\n",
    "\n",
    "# Print the Classification Report\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
